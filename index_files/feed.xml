<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" 
    xmlns:dc="http://purl.org/dc/elements/1.1/"
    xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
    xmlns:admin="http://webns.net/mvcb/"
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd">
	<channel>
<title>Bingcheng&#x27;s Notes</title><link>https://bingcheng.openmc.cn/notes/index.html</link><description>About coding&#x2c; about machine learning</description><dc:language>en</dc:language><language>en</language><dc:creator>Bingcheng HU</dc:creator><dc:rights>Copyright 2018-2020&#x2c; Bingcheng HU</dc:rights><dc:date>2020-09-27T11:49:45+08:00</dc:date><admin:generatorAgent rdf:resource="http://www.realmacsoftware.com/" />
<sy:updatePeriod>hourly</sy:updatePeriod>
<sy:updateFrequency>1</sy:updateFrequency>
<sy:updateBase>2000-01-01T12:00+00:00</sy:updateBase>
<lastBuildDate>Sun, 27 Sep 2020 12:12:20 +0800</lastBuildDate><item><title>Caution&#x21; max(0&#x2c; -) in back prop</title><dc:creator>Bingcheng HU</dc:creator><category>Machine Learning</category><dc:date>2020-09-27T11:49:45+08:00</dc:date><link>https://bingcheng.openmc.cn/notes/index_files/4a7dc00e96993d57c83ff6a530abff37-2.html#unique-entry-id-2</link><guid isPermaLink="true">https://bingcheng.openmc.cn/notes/index_files/4a7dc00e96993d57c83ff6a530abff37-2.html#unique-entry-id-2</guid><content:encoded><![CDATA[However, in back propagation, there is one point that could easily be ignored: we should set dx[x<=0] = 0 instead of dx[x<0] = 0!


...This line dhidd_layer[hidd_layer<=0] = 0 is signficant, if you use dhidd_layer[hidd_layer<0] = 0 instead, then in  gradient inspection, you will get a very large difference.
]]></content:encoded></item><item><title>Bias regularization</title><dc:creator>Bingcheng HU</dc:creator><category>Machine Learning</category><dc:date>2020-09-27T08:32:20+08:00</dc:date><link>https://bingcheng.openmc.cn/notes/index_files/Bias-regularization.html#unique-entry-id-0</link><guid isPermaLink="true">https://bingcheng.openmc.cn/notes/index_files/Bias-regularization.html#unique-entry-id-0</guid><content:encoded><![CDATA[As we already mentioned in the Linear Classification section, it is not common to regularize the bias parameters because they do not interact with the data through multiplicative interactions, and therefore do not have the interpretation of controlling the influence of a data dimension on the final objective. ...  This is likely because there are very few bias terms compared to all the weights, so the classifier can &ldquo;afford to&rdquo; use the biases if it needs them to obtain a better data loss.]]></content:encoded></item></channel>
</rss>